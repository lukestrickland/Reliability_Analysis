---
title: "Automation Failures in ATC: Standard Results"
author: "ljgs"
date: "20/11/2019"
output:
  word_document:
    reference_docx: ../assets/apa.docx
  pdf_document: default
  html_document: default
---
by Luke Strickland

```{r load_packages_and_data, echo= FALSE , results = "hide", message=FALSE, warning=FALSE}

source("dmc/dmc.R")
source("dmc/dmc_extras.R")
source("R/0-analysis_functions.R")
load_model ("LBA", "lba_B.R")

theme_set(theme_simple())

library(dplyr)
library(tidyr)
library(ggplot2)
library(pander)
library(snowfall)
options(digits=2)

fitpath <- file.path(set_fit_path(), "Reliability_Analysis")
loadpath <- create_loadpath(fitpath)
savepath <- create_savepath(fitpath)

loadpath("CA_top_samples_A_lb_final.RData")

CA_top_samples <- CA_top_samples_A_lb

# 
# pp <- h.post.predict.dmc(CA_top_samples, save.simulation = TRUE, cores=8)
# 
rescore_column <- function(df) {
  df$R <- factor(as.character(toupper(substr(df$S,1,1))==df$R))
  new_data <- attr(df, "data")
  new_data$R <- factor(as.character(toupper(substr(new_data$S,1,1))==new_data$R))
#  new_data <- new_data %>% select(C, everything())
  #%>% select(-R)
  attr(df, "data") <- new_data
#  df %>% select(reps, C, everything())
  #%>% select(-R)
  df
}
# 
# savepath(pp,
#      file="CA_top_samples_pp_A_lb.RData")

# loadpath("CA_top_samples_pp_A_lb.RData")
# 
# pp1 <- lapply(pp, rescore_column)
# 


tmp <- names(CA_top_samples_A_lb)
tmp <- tmp[!tmp=="4"]
# tmp <- tmp[!tmp=="26"]
full_balance <- tmp

CA_top_samples <- CA_top_samples[names(CA_top_samples) %in% full_balance]
# pp1 <- pp1[names(pp1) %in% full_balance]
# 
# fitlist <- GET.fitgglist.dmc(pp1, factors=c("cond", "failtrial"))
# savepath(fitlist, file="fitlist_A_lb_27.RData")

# loadpath("fitlist_A_lb_27.RData")
# loadpath("postexp_summaries_A_lb.RData")
loadpath("model_correlations_A_lb_27.RData")


```

*Table 2*. 
Statistical tests of automation-induced excitation and inhibition effects. We depict Z(p), where Z is the posterior mean of the parameter difference divided by its standard deviation, and p is the one-tailed posterior probability against their being an effect. L stands for low-reliability condition and H for the high-reliability condition. 

```{r echo= FALSE ,results = "hide", message=FALSE, warning=FALSE, results='asis'}

H_conf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.fail.true",, drop=F] - 
           thetas[,"mean_v.cc.H.fail.true",, drop=F])

H_conf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.H.fail.false",, drop=F] - 
          thetas[,"mean_v.cc.M.fail.false",, drop=F] 
           )

H_conf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.H.nonf.true",, drop=F] -
          thetas[,"mean_v.cc.M.nonf.true",, drop=F] 
           )

H_conf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.cc.H.nonf.false",, drop=F])



H_nonconf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.fail.true",, drop=F] - 
           thetas[,"mean_v.nn.H.fail.true",, drop=F])

H_nonconf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.H.fail.false",, drop=F] - 
          thetas[,"mean_v.nn.M.fail.false",, drop=F] 
           )

H_nonconf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.H.nonf.true",, drop=F] -
          thetas[,"mean_v.nn.M.nonf.true",, drop=F] 
           )

H_nonconf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.nn.H.nonf.false",, drop=F])



L_conf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.fail.true",, drop=F] - 
           thetas[,"mean_v.cc.L.fail.true",, drop=F])

L_conf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.L.fail.false",, drop=F] - 
          thetas[,"mean_v.cc.M.fail.false",, drop=F] 
           )

L_conf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.L.nonf.true",, drop=F] -
          thetas[,"mean_v.cc.M.nonf.true",, drop=F] 
           )

L_conf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.cc.L.nonf.false",, drop=F])



L_nonconf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.fail.true",, drop=F] - 
           thetas[,"mean_v.nn.L.fail.true",, drop=F])

L_nonconf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.L.fail.false",, drop=F] - 
          thetas[,"mean_v.nn.M.fail.false",, drop=F] 
           )

L_nonconf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.L.nonf.true",, drop=F] -
          thetas[,"mean_v.nn.M.nonf.true",, drop=F] 
           )

L_nonconf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.nn.L.nonf.false",, drop=F])





inhextab <- rbind(
  c("", "", "", ""),
  c(L_conf_ex_success, L_conf_inh_success, H_conf_ex_success, H_conf_inh_success),
  c(L_conf_ex_fail, L_conf_inh_fail, H_conf_ex_fail, H_conf_inh_fail),
  c("", "", "", ""),
  c(L_nonconf_ex_success, L_nonconf_inh_success, H_nonconf_ex_success, H_nonconf_inh_success),
  c(L_nonconf_ex_fail, L_nonconf_inh_fail, H_nonconf_ex_fail, H_nonconf_inh_fail)
  
      )

rownames(inhextab) <- c("Conflict Trials", "Automation Correct", "Automation Incorrect",
                        "Non-conflict Trials", "Automation Correct", "Automation Incorrect")
colnames(inhextab) <- c("Excitation (L)", "Inhibition (L)", "Excitation (H)", "Inhibition (H)")

pandoc.table(inhextab)


```

Table 3. 
*Statistical tests of differences in thresholds across automated and manual conditions. We depict Z(p), where Z is the posterior mean of the parameter difference divided by its standard deviation, and p is the one-tailed posterior probability against their being an effect.*

```{r echo= FALSE , results = "asis", message=FALSE, warning=FALSE, fig.width = 8, fig.height=6}

B_N_1_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.N",, drop=F] -
          thetas[,"B.L.1.N",, drop=F] 
           )

B_N_2_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.N",, drop=F] -
          thetas[,"B.L.2.N",, drop=F] 
           )

B_N_3_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.N",, drop=F] -
          thetas[,"B.L.3.N",, drop=F] 
           )



B_C_1_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.C",, drop=F] -
          thetas[,"B.L.1.C",, drop=F] 
           )

B_C_2_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.C",, drop=F] -
          thetas[,"B.L.2.C",, drop=F] 
           )

B_C_3_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.C",, drop=F] -
          thetas[,"B.L.3.C",, drop=F] 
           )



B_N_1_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.N",, drop=F] -
          thetas[,"B.H.1.N",, drop=F] 
           )

B_N_2_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.N",, drop=F] -
          thetas[,"B.H.2.N",, drop=F] 
           )

B_N_3_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.N",, drop=F] -
          thetas[,"B.H.3.N",, drop=F] 
           )



B_C_1_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.C",, drop=F] -
          thetas[,"B.H.1.C",, drop=F] 
           )

B_C_2_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.C",, drop=F] -
          thetas[,"B.H.2.C",, drop=F] 
           )

B_C_3_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.C",, drop=F] -
          thetas[,"B.H.3.C",, drop=F] 
           )


Btab <- rbind(
  c(B_C_1_MvL, B_C_2_MvL, B_C_3_MvL),
  c(B_N_1_MvL, B_N_2_MvL, B_N_3_MvL),
  c(B_C_1_MvH, B_C_2_MvH, B_C_3_MvH),
  c(B_N_1_MvH, B_N_2_MvH, B_N_3_MvH)

      )

rownames(Btab) <- c("Conflict Accumulator (L)",
                    "Non-conflict Accumulator (L)",
                    "Conflict Accumulator (H)",
                    "Non-conflict Accumulator (H)")
colnames(Btab) <- c("Session One", "Session Two", "Session Three")

pandoc.table(Btab)



```



# Individual differences

We explored how individual differences in model parameters related to the costs and benefits of automation to accuracy. To do so, we constructed distributions of “plausible value” correlations (Ly et al., 2017), in which a correlation between model parameters and the data of interest is calculated for every posterior sample, creating a distribution of correlations. We then adjusted this plausible value distribution to correct for population-level inference (Ly et al., 2018). This approach of correcting for sample size is quite conservative, and so we are confident that trends identified by this method are robust. In Table 3 we report posterior mean values of these correlations and accompanying 95% credible intervals. In text we refer to “plausible” correlations as those with 95% credible intervals not overlapping 0. For our correlations we obtained a single estimate of excitation and inhibition for each participant by averaging over conflict and non-conflict trials, and over automation-correct and automation-incorrect trials. 

Table 4.
*Plausible value correlations between model mechanisms, benefits of automation, costs of automation, and trust in automation. We constructed distributions of "plausible values" (Ly et al., 2017) of correlations by calculating the correlation across participants between model parameters and dependent variables for every posterior sample.  This was then corrected for population-level inference (Ly et al., 2018). We report posterior mean (95% credible interval) of these correlation distributions. We obtained a single estimate of excitation and inhibition for each participant by averaging over conflict and non-conflict trials, and over automation-correct and automation-incorrect trials*

```{r echo= FALSE , results = "asis", message=FALSE, warning=FALSE, fig.width = 8, fig.height=6}




MCIs <- function(MCI){
  MCI <- round(MCI, 2)
  paste0(MCI["M"], " (", MCI["LCI"], " - ", MCI["HCI"], ")")
  
}

cortab <- rbind(
  c("", ""),
  c(MCIs(ex_L_benefit), MCIs(inh_L_benefit)),
  c(MCIs(ex_L_cost), MCIs(inh_L_cost)),
  c(MCIs(ex_L_benefit_RT), MCIs(inh_L_benefit_RT)),
  c(MCIs(ex_L_cost_RT), MCIs(inh_L_cost_RT)), 
  c(MCIs(ex_L_trust), MCIs(inh_L_trust)), 
  c("", ""),
  c(MCIs(ex_H_benefit), MCIs(inh_H_benefit)),
  c(MCIs(ex_H_cost), MCIs(inh_H_cost)),
  c(MCIs(ex_H_benefit_RT), MCIs(inh_H_benefit_RT)),
  c(MCIs(ex_H_cost_RT), MCIs(inh_H_cost_RT)),
  c(MCIs(ex_H_trust), MCIs(inh_H_trust))
)

rownames(cortab) <- c("Low Reliability", "Accuracy Benefit", "Accuracy Cost", "RT Benefit",
                        "RT Cost", "Trust",
                      "High Reliability",
                      "Accuracy Benefit", "Accuracy Cost", "RT Benefit",
                        "RT Cost", "Trust")
colnames(cortab) <- c("Excitation ", "Inhibition ")

pandoc.table(cortab)

```