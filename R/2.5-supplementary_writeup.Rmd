---
title: "Automation Failures in ATC: Supplementary Results"
author: "ljgs"
date: "20/11/2019"
output:
  word_document: default
  html_document: default
  pdf_document: default
---
by Luke Strickland

```{r load_packages_and_data, echo= FALSE , results = "hide", message=FALSE, warning=FALSE}

library(dplyr)
library(ggplot2)
library(lme4)
library(car)
library(lsmeans)
library(gridExtra)
library(pander)
options(digits=2)
source("R/0-analysis_functions.R")

load("img/cleandats.RData")

cleandats <- cleandats %>% mutate(C = toupper(S)==R)

colnames(cleandats)[colnames(cleandats)=="sess"] <- "Session"
colnames(cleandats)[colnames(cleandats)=="cond"] <- "Condition"
colnames(cleandats)[colnames(cleandats)=="S"] <- "Stimulus"
colnames(cleandats)[colnames(cleandats)=="failtrial"] <- "Automation"

cleandats$Session <- factor(cleandats$Session, levels=c("1", "2", "3"),
                      labels=c("One", "Two", "Three"))

cleandats$Condition <- factor(cleandats$Condition , levels=c("AUTO_L", "AUTO_H", "MANUAL"),
                      labels=c("Automation_Low", "Automation_High", "Manual"))

cleandats$Automation <- factor(cleandats$Automation, levels=c("nonf", "fail"),
                      labels=c("Automation Success", "Automation Failure"))

cleandats$Stimulus <- factor(cleandats$Stimulus, levels=c("c", "n"),
                      labels=c("Conflict", "Non-conflict"))


tmp <- 1:24
tmp <- tmp[!tmp==4]
full_balance <- c(tmp, 28) 

cleandats <- cleandats %>% filter(s %in% full_balance)

theme_set(theme_simple())

accs <-
  cleandats %>% group_by(s, Stimulus, Condition, Automation, Session) %>% 
  filter(!is.na(R)) %>% summarise(acc = mean(C)) %>%
  arrange(s) %>% arrange(Automation)

RTs <- cleandats %>% group_by(s, Stimulus, Condition, Automation, Session) %>% 
  filter(C) %>% 
  summarise(RT=mean(RT))%>% arrange(Automation)


```

Table S1

*Wald Chi-Square significance tests for conflict detection accuracy. A generalized linear
mixed-effects model was fitted to every trial, with a binomial probit link 
function. Random intercepts were included for each
participant. In addition to examining experimental condition (automated vs manual),
'Automation' (a factor denoting whether the automation succeeded or failed)
and stimulus type (conflict/non-conflict), 
we included a 'session' factor to account for
effects of task repetition.*

```{r accuracy_model, echo= FALSE, message=TRUE, warning=TRUE, results="asis"}
# 
# acc_glmer_top <-
#   glmer(C ~ Stimulus * Condition * Session * Automation + (1 |s),
#         data = cleandats,
#         family = binomial(link = "probit"))


# save(acc_glmer_top, file = "img/acc_model.RData")

load("img/acc_model.RData")

pandoc.table(
  make_model_table(Anova(acc_glmer_top,type="II")))

```

Table S2

*Follow up significance tests of the difference in conflict detection accuracy
across experimental sessions. 
The z.ratio is the mean of the effect divided by its standard error.
Tukey adjustments were applied to the included p-values.*

```{r accuracy_session, echo= FALSE, message=FALSE, warning=FALSE, results="asis",fig.height = 3, fig.width = 4}

emms_Session <- emmeans(acc_glmer_top, specs=~Session)

make_contrast_table(
  summary(
  contrast(emms_Session, method=list("Session 1 - Session 2"= c(1,-1,0), 
                                   "Session 2 - Session 3"= c(0,1,-1)))
  )
)



```


Table S3

*Follow up significance tests of the difference in conflict detection accuracy
across conditions, conditional on whether the automation succeeded or failed. 
The z.ratio is the mean of the effect divided by its standard error.
Tukey adjustments were applied to the included p-values.*

```{r ldt_accuracy_trial_range, echo= FALSE, message=FALSE, warning=FALSE, results="asis",fig.height = 3, fig.width = 4}

summary_Condition_Automation <- summary(contrast(emmeans(acc_glmer_top, specs=~Condition|Automation), method="pairwise"))

make_contrast_table(summary_Condition_Automation)  


```




Table S4

*Wald Chi-Square significance tests for ongoing task RT. A linear
mixed-effects model was fitted to mean correct PM RTs. Random intercepts were included for each
participant. In addition to examining experimental condition (automated vs manual),
'Automation' (a factor denoting whether the automation succeeded or failed)
and stimulus type (conflict/non-conflict), 
we included a 'session' factor to account for
effects of task repetition.*

```{r RT_model, echo= FALSE, message=TRUE, warning=TRUE, results="asis"}

RT_model <- lmer(RT ~ Stimulus * Condition * Session * Automation + (1 |s),
     data = RTs)

pandoc.table(
  make_model_table(Anova(RT_model, type="II")))

```

Table S5

*Follow up significance tests of the difference in RT
across experimental sessions. 
The z.ratio is the mean of the effect divided by its standard error.
Tukey adjustments were applied to the included p-values.*

```{r accuracy_session, echo= FALSE, message=FALSE, warning=FALSE, results="asis",fig.height = 3, fig.width = 4}

emms_Session_RT <- emmeans(RT_model, specs=~Session)

make_contrast_table(
  summary(
  contrast(emms_Session_RT, method=list("Session 1 - Session 2"= c(1,-1,0), 
                                   "Session 2 - Session 3"= c(0,1,-1)))
  )
)



```


Table S6

*Follow up significance tests of the differences in RT across
experimental conditions, conditional on whether the automation
succeeded or failed. Tukey adjustments were applied to the included p-values.*

```{r RT_contrasts_1, echo= FALSE, message=FALSE, warning=FALSE, results="asis"}

summary_Condition_Automation_RT <- summary(contrast(emmeans(RT_model, specs=~Condition|Automation), method="pairwise"))

make_contrast_table(summary_Condition_Automation_RT) 

```

