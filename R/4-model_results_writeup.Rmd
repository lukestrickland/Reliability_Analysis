---
title: "Automation Failures in ATC: Standard Results"
author: "ljgs"
date: "20/11/2019"
output:
  word_document:
    reference_docx: ../assets/apa.docx
  pdf_document: default
  html_document: default
---
by Luke Strickland

```{r load_packages_and_data, echo= FALSE , results = "hide", message=FALSE, warning=FALSE}

source("dmc/dmc.R")
source("dmc/dmc_extras.R")
source("R/0-analysis_functions.R")
load_model ("LBA", "lba_B.R")

theme_set(theme_simple())

library(dplyr)
library(tidyr)
library(ggplot2)
library(pander)
library(snowfall)
options(digits=2)

fitpath <- file.path(set_fit_path(), "Reliability_Analysis")
loadpath <- create_loadpath(fitpath)
savepath <- create_savepath(fitpath)

loadpath("CA_top_samples_A_lb_final.RData")

CA_top_samples <- CA_top_samples_A_lb

# 
# pp <- h.post.predict.dmc(CA_top_samples, save.simulation = TRUE, cores=8)
# 
rescore_column <- function(df) {
  df$R <- factor(as.character(toupper(substr(df$S,1,1))==df$R))
  new_data <- attr(df, "data")
  new_data$R <- factor(as.character(toupper(substr(new_data$S,1,1))==new_data$R))
#  new_data <- new_data %>% select(C, everything())
  #%>% select(-R)
  attr(df, "data") <- new_data
#  df %>% select(reps, C, everything())
  #%>% select(-R)
  df
}
# 
# savepath(pp,
#      file="CA_top_samples_pp_A_lb.RData")

loadpath("CA_top_samples_pp_A_lb.RData")

pp1 <- lapply(pp, rescore_column)



tmp <- 1:24
tmp <- tmp[!tmp==4]
full_balance <- c(tmp, 28) 

CA_top_samples <- CA_top_samples[names(CA_top_samples) %in% full_balance]
pp1 <- pp1[names(pp1) %in% full_balance]
# 
# fitlist <- GET.fitgglist.dmc(pp1, factors=c("cond", "failtrial"))
# savepath(fitlist, file="fitlist_A_lb.RData")

loadpath("fitlist_A_lb.RData")

```

# Model Fit

We obtained Bayesian estimates of model parameters using the Dynamic Models of Choice R Suite (Heathcote et al., 2018). These estimates take the form of posterior distributions, which are proportional to probability distributions of the model parameters given the data and prior information about the parameter values. The details of estimation are discussed in the supplementary materials. Figure 7 displays fit of the posterior predictions of the model to the data. Generally, the model fitted the data well, including the effects of automation on accuracy and distributions of RT. There was some minor miss-fit to median correct RT in the high-reliability condition, with
the model somewhat underestimating the slowing induced by the automation. However, it is worth noting that the model was able to fit the direction of this effect, and that this represents a small number of responses (there are relatively few trials where the automation was incorrect in the high-reliability condition).

```{r echo= FALSE}
pp_cap <- "Figure 7. Posterior predictions of performance, averaged over participants. The model predictions correspond to the white circles, the posterior means correspond to the black shaded dots. The error bars display the 95% posterior credible intervals of the predictions. Three quantiles of response time (RT) are depicted, with the 0.1 quantile of RT grouped on the bottom, the median RT at the middle, and the 0.9 quantile of RT at the top."
```

```{r accuracy_descriptives_fortext, echo= FALSE, message=FALSE, warning=FALSE, fig.height = 7, fig.width=7, fig.cap=pp_cap}



accs <- fitlist$pps %>% filter(R=="TRUE") %>% select(-R)

accs$cond <- factor(accs$cond, levels=c("M", "L", "H"), labels =
                      c("Manual", "Low Reliability", "High Reliability"))

accs$failtrial <- factor(accs$failtrial, levels=c("nonf", "fail"), labels =
                      c("Automation Correct", "Automation Incorrect"))

plot1 <- ggplot.RP.dmc(accs, xaxis="cond") +xlab("") +ylab("Accuracy")

corRTs <- fitlist$RTs %>% filter(R=="TRUE") %>% select(-R)

corRTs$cond <- factor(corRTs$cond, levels=c("M", "L", "H"), labels =
                      c("Manual", "Low Reliability", "High Reliability"))

corRTs$failtrial <- factor(corRTs$failtrial, levels=c("nonf", "fail"), labels =
                      c("Automation Correct", "Automation Incorrect"))

plot2 <- ggplot.RT.dmc(corRTs, xaxis="cond") +xlab("") +ylab("Correct RT")



errRTs <- fitlist$RTs %>% filter(R=="FALSE") %>% select(-R)

errRTs$cond <- factor(errRTs$cond, levels=c("M", "L", "H"), labels =
                      c("Manual", "Low Reliability", "High Reliability"))

errRTs$failtrial <- factor(errRTs$failtrial, levels=c("nonf", "fail"), labels =
                      c("Automation Correct", "Automation Incorrect"))

plot3 <- ggplot.RT.dmc(errRTs, xaxis="cond") +xlab("") +ylab("Error RT")


grid.arrange(plot1,plot2,plot3)


```

```{r evaluate_model_params_calc, echo= FALSE , results = "hide", message=FALSE, warning=FALSE}

# msds <-
#   get.msds(CA_top_samples[names(CA_top_samples) %in% full_balance])
# # 
# savepath(msds, file=
#       "msds_top_samples_balance_A_lb.RData")
# # 
# msds <-
#   get.msds(CA_top_samples[names(CA_top_samples) != "4"])
# 
# save(msds, file=
#       "samples_data/msds_top_samples.RData")
# 


loadpath("msds_top_A_lb.RData")

paste.msd <- function(x) paste(signif(x["M"],2), "(", 
                               signif(x["SD"],2), ")", sep="")
zpvec <- function(samples, fun){
    effect<- group.inference.dist(samples, fun)
    Z <- mean(effect)/sd(effect)
    p <- minp(effect)
    if(p<.001) p <- "< .001" else {
      p = round(p,3)
      p= paste("= .", 
      substr(p,3,10), sep="")
    }
    c(round(Z,2), p)
}
```


# Parameter Inference

For inference we created a group-averaged posterior distribution, by averaging the values of each posterior sample across participants. The values of the averaged model parameters are tabulated in the supplementary materials. In the following sections, we examine the effect of automation on accumulation rate and threshold parameters. To test parameter differences, we calculate a one-tailed posterior *p* value, corresponding to the proportion of posterior samples on which one parameter value was higher than another. To accord with the typical intuition associated with *p* values, we report the *p* value against whichever direction was closest to an observed effect (e.g., a *p* of 0 is evidence in favor of an effect). Many effects were ‘significant’ in the sense that *p* < .001. To give an estimate of effect size, we report the mean of the parameter differences divided by the standard deviation, referred to as *Z*.
 

# Excitation and Inhibition

Evidence accumulation rates are plotted in Figure 8. The effects of automation are evaluated by comparing the accumulation rate towards an automation trial with the corresponding accumulation rates in manual conditions. Excitation is indicated by increased accumulation towards the accumulator that agrees with the decision aid (i.e., match). For example, on a conflict trial on which the automation correctly recommends ‘conflict’, excitation would increase the conflict accumulation rate. Inhibition is indicated by reduced accumulation towards the accumulator that disagrees with the decision aid (i.e., mismatch). For example, for conflict trials on which the decision aid correctly labels a conflict, inhibition would reduce accumulation in the ‘non-conflict’ accumulator.

Table 2 contains our statistical tests of excitation and inhibition effects. We found evidence 
of both excitation and inhibition in both conditions. These effects were particularly strong in the high-reliability condition. In the low-reliability condition, excitation effects were relatively weaker than inhibition effects.

```{r echo= FALSE}
Vs_cap <- "Figure 8. Estimates of accumulation rates. The shapes indicate the posterior means and the error bars correspond to the mean plus or minus the posterior standard deviation."
```

```{r echo=FALSE, fig.cap=Vs_cap, fig.height=6, fig.width=8, message=FALSE, warning=FALSE, results="hide"}
Vs <- msds[grep("mean_v", rownames(msds)),]

Vs$Cond <- "Manual" 
Vs$Cond[grep("L", rownames(Vs))] <- "Low"
Vs$Cond[grep("H", rownames(Vs))] <- "High"
Vs$Auto <- "Automation Correct"
Vs$Auto[grep("fail", rownames(Vs))] <- "Automation Incorrect"
Vs$S <- "Conflict"
Vs$S[grep("nn", rownames(Vs))] <- "Non-conflict"
Vs$match <- "Match"
Vs$match[grep("false", rownames(Vs))] <- "Mismatch"

names(Vs)[names(Vs)=="Cond"] <- "Condition"

Vs$exinh <- NA
Vs$exinh[Vs$Auto=="Automation Correct" & Vs$match=="Match"] <- "Excitation"
Vs$exinh[Vs$Auto=="Automation Incorrect" & Vs$match=="Match"] <- "Inhibition"
Vs$exinh[Vs$Auto=="Automation Correct" & Vs$match=="Mismatch"] <- "Inhibition"
Vs$exinh[Vs$Auto=="Automation Incorrect" & Vs$match=="Mismatch"] <- "Excitation"


ggplot(Vs, aes(factor(Auto),M)) + 
  geom_point(stat = "identity",aes(shape=Condition, col=Condition), size=2.5) +
  geom_errorbar(aes(ymax = M + SD, ymin = M - SD, width = 0.3, col=Condition))+ 
  ylab("Accumulation Rate") + xlab("")+
  facet_grid(S ~ match,scales = "free", space = "free") +
    theme(text = element_text(size = 12))

```

Table 2
*Statistical tests of automation-induced excitation and inhibition effects. We depict Z(p), where Z is the posterior mean of the parameter difference divided by its standard deviation, and p is the one-tailed posterior probability against their being an effect.*

```{r echo= FALSE ,results = "hide", message=FALSE, warning=FALSE, results='asis'}

H_conf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.fail.true",, drop=F] - 
           thetas[,"mean_v.cc.H.fail.true",, drop=F])

H_conf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.H.fail.false",, drop=F] - 
          thetas[,"mean_v.cc.M.fail.false",, drop=F] 
           )

H_conf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.H.nonf.true",, drop=F] -
          thetas[,"mean_v.cc.M.nonf.true",, drop=F] 
           )

H_conf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.cc.H.nonf.false",, drop=F])



H_nonconf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.fail.true",, drop=F] - 
           thetas[,"mean_v.nn.H.fail.true",, drop=F])

H_nonconf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.H.fail.false",, drop=F] - 
          thetas[,"mean_v.nn.M.fail.false",, drop=F] 
           )

H_nonconf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.H.nonf.true",, drop=F] -
          thetas[,"mean_v.nn.M.nonf.true",, drop=F] 
           )

H_nonconf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.nn.H.nonf.false",, drop=F])



L_conf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.fail.true",, drop=F] - 
           thetas[,"mean_v.cc.L.fail.true",, drop=F])

L_conf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.L.fail.false",, drop=F] - 
          thetas[,"mean_v.cc.M.fail.false",, drop=F] 
           )

L_conf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.L.nonf.true",, drop=F] -
          thetas[,"mean_v.cc.M.nonf.true",, drop=F] 
           )

L_conf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.cc.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.cc.L.nonf.false",, drop=F])



L_nonconf_inh_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.fail.true",, drop=F] - 
           thetas[,"mean_v.nn.L.fail.true",, drop=F])

L_nonconf_ex_fail <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.L.fail.false",, drop=F] - 
          thetas[,"mean_v.nn.M.fail.false",, drop=F] 
           )

L_nonconf_ex_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.L.nonf.true",, drop=F] -
          thetas[,"mean_v.nn.M.nonf.true",, drop=F] 
           )

L_nonconf_inh_success <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"mean_v.nn.M.nonf.false",, drop=F] - 
           thetas[,"mean_v.nn.L.nonf.false",, drop=F])





inhextab <- rbind(
  c("", "", "", ""),
  c(L_conf_ex_success, L_conf_inh_success, H_conf_ex_success, H_conf_inh_success),
  c(L_conf_ex_fail, L_conf_inh_fail, H_conf_ex_fail, H_conf_inh_fail),
  c("", "", "", ""),
  c(L_nonconf_ex_success, L_nonconf_inh_success, H_conf_ex_success, H_nonconf_inh_success),
  c(L_nonconf_ex_fail, L_nonconf_inh_fail, H_conf_ex_fail, H_nonconf_inh_fail)
  
      )

rownames(inhextab) <- c("Conflict Trials", "Automation Correct", "Automation Incorrect",
                        "Non-conflict Trials", "Automation Correct", "Automation Incorrect")
colnames(inhextab) <- c("Excitation (L)", "Inhibition (L)", "Excitation (H)", "Inhibition (H)")

pandoc.table(inhextab)


```


# Threshold effects

Threshold estimates are plotted in Figure 9. Statistical tests of differences across automated and manual conditions in thresholds are tabulated in Table 3. There were some small drops in threshold levels in the low-reliability condition compared with the manual condition, suggesting participants may have become less cautious when provided with automation. There were relatively stronger decreases in thresholds observed in the high-reliability condition. However, our 
supplementary analysis, where we explored how parameters affected the predictions of our model,
we found that thresholds played a relatively minor role in the effects of automation on performance.


```{r echo= FALSE}
Bs_cap <- "Figure 9. Estimates of thresholds. The shapes indicate the posterior means and the error bars correspond to the mean plus or minus the posterior standard deviation."
```

```{r echo= FALSE , results = "hide", message=FALSE, warning=FALSE, fig.cap = Bs_cap, fig.width = 8, fig.height=3}
Bs <- msds[grep("B", rownames(msds)),]

Bs$R <- "Non-conflict"
Bs$R[grep("C", rownames(Bs))] <- "Conflict"
Bs$Cond <- "Manual"
Bs$Cond[grep("L", rownames(Bs))] <- "Low"
Bs$Cond[grep("H", rownames(Bs))] <- "High"
Bs$Session <- "Session One"
Bs$Session[grep("2", rownames(Bs))] <- "Session Two"
Bs$Session[grep("3", rownames(Bs))] <- "Session Three"

Bs$Session <- factor(Bs$Session, levels=c("Session One", "Session Two", "Session Three"))


names(Bs)[names(Bs)=="Cond"] <- "Condition"

ggplot(Bs, aes(factor(R),M)) + 
  geom_point(stat = "identity",aes(col=Condition, shape=Condition), size=2.5) +
  geom_errorbar(aes(ymax = M + SD, ymin = M - SD, width = 0.3, col=Condition))+ 
  ylab("Threshold") + xlab("Accumulator")+
  facet_grid(.~Session)


```

Table 3 
*Statistical tests of differences in thresholds across automated and manual conditions. We depict Z(p), where Z is the posterior mean of the parameter difference divided by its standard deviation, and p is the one-tailed posterior probability against their being an effect.*

```{r echo= FALSE , results = "asis", message=FALSE, warning=FALSE, fig.width = 8, fig.height=6}

B_N_1_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.N",, drop=F] -
          thetas[,"B.L.1.N",, drop=F] 
           )

B_N_2_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.N",, drop=F] -
          thetas[,"B.L.2.N",, drop=F] 
           )

B_N_3_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.N",, drop=F] -
          thetas[,"B.L.3.N",, drop=F] 
           )



B_C_1_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.C",, drop=F] -
          thetas[,"B.L.1.C",, drop=F] 
           )

B_C_2_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.C",, drop=F] -
          thetas[,"B.L.2.C",, drop=F] 
           )

B_C_3_MvL <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.C",, drop=F] -
          thetas[,"B.L.3.C",, drop=F] 
           )



B_N_1_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.N",, drop=F] -
          thetas[,"B.H.1.N",, drop=F] 
           )

B_N_2_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.N",, drop=F] -
          thetas[,"B.H.2.N",, drop=F] 
           )

B_N_3_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.N",, drop=F] -
          thetas[,"B.H.3.N",, drop=F] 
           )



B_C_1_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.1.C",, drop=F] -
          thetas[,"B.H.1.C",, drop=F] 
           )

B_C_2_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.2.C",, drop=F] -
          thetas[,"B.H.2.C",, drop=F] 
           )

B_C_3_MvH <- zandp(CA_top_samples, 
        function (thetas)
          thetas[,"B.M.3.C",, drop=F] -
          thetas[,"B.H.3.C",, drop=F] 
           )


Btab <- rbind(
  c(B_C_1_MvL, B_C_2_MvL, B_C_3_MvL),
  c(B_N_1_MvL, B_N_2_MvL, B_N_3_MvL),
  c(B_C_1_MvH, B_C_2_MvH, B_C_3_MvH),
  c(B_N_1_MvH, B_N_2_MvH, B_N_3_MvH)

      )

rownames(Btab) <- c("Conflict Accumulator (L)",
                    "Non-conflict Accumulator (L)",
                    "Conflict Accumulator (H)",
                    "Non-conflict Accumulator (H)")
colnames(Btab) <- c("Session One", "Session Two", "Session Three")

pandoc.table(Btab)



```
